{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 导入numpy \n",
    "import numpy as np\n",
    "# 导入word2vec 文字转向量包\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "# 导入jieba分词\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从文本读取数据\n",
    "def load_data(file):\n",
    "    data = open(file)\n",
    "    return data.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9190dc222d16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9190dc222d16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mY_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mY_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mclass_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mY_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mY_value\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "data = load_data('data3.txt')\n",
    "# 处理文本数据分离文本和标签\n",
    "X=[]\n",
    "Y_=[]\n",
    "for i in data:\n",
    "    text = i.split('***',1)\n",
    "    print(len(text))\n",
    "    try:\n",
    "        text[0]\n",
    "        text[1]\n",
    "    except:\n",
    "        X.append(text[0]) \n",
    "        Y_.append(text[1].replace('\\n',''))\n",
    "Y_value = list(set(Y_))\n",
    "class_data = {i:Y_value.index(i) for i in Y_value}\n",
    "Y_data = [class_data[i] for i in Y_]\n",
    "# 转为onehot编码\n",
    "Y = to_categorical(np.array(Y_data))\n",
    "print(Y)\n",
    "# 处理文本\n",
    "sentences_list = []\n",
    "for line in X:\n",
    "    single_list = line.strip().split(' ')\n",
    "    single_list = jieba.analyse.extract_tags(single_list[0],topK=20,withWeight=False,allowPOS=())\n",
    "    while '' in single_list:\n",
    "        single_list.remove('')\n",
    "    sentences_list.append(single_list)\n",
    "print(sentences_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用word2vec 模型返回字典和词的向量\n",
    "\n",
    "def create_dictionaries(model):\n",
    "    gensim_dict = Dictionary()\n",
    "    gensim_dict.doc2bow(model.wv.vocab.keys(),allow_update=True)\n",
    "    w2indx = {v:k+1 for k,v in gensim_dict.items()}\n",
    "    w2vec = {word:model[word] for word in w2indx.keys()}\n",
    "    return w2indx,w2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xms/.virtualenvs/dl/lib/python3.5/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# word2vec 方法转向量\n",
    "model = Word2Vec(sentences_list,size=100,min_count=5,window=5)\n",
    "index_dict,word_vectors = create_dictionaries(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1982, 100)\n"
     ]
    }
   ],
   "source": [
    "# 生成词嵌入向量\n",
    "# 把上边一个词向量的长度转为100\n",
    "n_symbols = len(index_dict) +1\n",
    "embedding_weights = np.zeros((n_symbols,100))\n",
    "for w,index in index_dict.items():\n",
    "    embedding_weights[index,:] = word_vectors[w]\n",
    "print(embedding_weights.shape)\n",
    "# 词有7767个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1773, 981, 404, 1410, 743]\n"
     ]
    }
   ],
   "source": [
    "# 在字典中找到词返回索引\n",
    "# 文本和词典匹配将我们的词特征转为数字\n",
    "def text_to_index_array(dic,sentence):\n",
    "    new_sentence = []\n",
    "    for sen in sentence:\n",
    "        new_sen = []\n",
    "        for word in sen:\n",
    "            try:\n",
    "                new_sen.append(dic[word])\n",
    "            except:\n",
    "                new_sen.append(0)\n",
    "        new_sentence.append(new_sen)\n",
    "    return np.array(new_sentence)\n",
    "\n",
    "x = text_to_index_array(index_dict,sentences_list)\n",
    "print(x[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense,Dropout,Activation\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6272, 50)\n"
     ]
    }
   ],
   "source": [
    "# 划分数据集生成训练和测试4:1\n",
    "# sklearn包划分数据\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,Y,test_size=0.2)\n",
    "# 把x输入特征标准化，不够的补0是每一个输入的x 为50长度\n",
    "x_train = sequence.pad_sequences(x_train,maxlen=50)\n",
    "x_test = sequence.pad_sequences(x_test,maxlen=50)\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xms/.virtualenvs/dl/lib/python3.5/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(units=50, activation=\"relu\", recurrent_activation=\"hard_sigmoid\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# 输入特征\n",
    "model.add(Embedding(output_dim=100,input_dim=n_symbols,mask_zero=True,weights=[embedding_weights]))\n",
    "# model.add(Dense(12))\n",
    "# lstm隐藏\n",
    "model.add(LSTM(output_dim=50,activation='relu',inner_activation='hard_sigmoid'))\n",
    "# 随机失活\n",
    "model.add(Dropout(0.5))\n",
    "# 全连接层 输出12个分类\n",
    "model.add(Dense(12))\n",
    "# softmax激活\n",
    "model.add(Activation('softmax'))\n",
    "# 多分类损失函数，梯度下降\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6272 samples, validate on 1568 samples\n",
      "Epoch 1/20\n",
      "6272/6272 [==============================] - 8s 1ms/step - loss: 2.2960 - acc: 0.2455 - val_loss: 2.1060 - val_acc: 0.3508\n",
      "Epoch 2/20\n",
      "6272/6272 [==============================] - 8s 1ms/step - loss: 1.8658 - acc: 0.4251 - val_loss: 1.6505 - val_acc: 0.5128\n",
      "Epoch 3/20\n",
      "6272/6272 [==============================] - 8s 1ms/step - loss: 1.5421 - acc: 0.5357 - val_loss: 1.5307 - val_acc: 0.5236\n",
      "Epoch 4/20\n",
      "6272/6272 [==============================] - 8s 1ms/step - loss: 1.3181 - acc: 0.5871 - val_loss: 1.3909 - val_acc: 0.5638\n",
      "Epoch 5/20\n",
      "6272/6272 [==============================] - 8s 1ms/step - loss: 1.1651 - acc: 0.6346 - val_loss: 1.3222 - val_acc: 0.5899\n",
      "Epoch 6/20\n",
      "6272/6272 [==============================] - 8s 1ms/step - loss: 1.0244 - acc: 0.6762 - val_loss: 1.2852 - val_acc: 0.5995\n",
      "Epoch 7/20\n",
      "6272/6272 [==============================] - 8s 1ms/step - loss: 0.9381 - acc: 0.7100 - val_loss: 1.2800 - val_acc: 0.6097\n",
      "Epoch 8/20\n",
      "6272/6272 [==============================] - 8s 1ms/step - loss: 0.8462 - acc: 0.7337 - val_loss: 1.3102 - val_acc: 0.6193\n",
      "Epoch 9/20\n",
      "6272/6272 [==============================] - 8s 1ms/step - loss: 0.7604 - acc: 0.7546 - val_loss: 1.3086 - val_acc: 0.6237\n",
      "Epoch 10/20\n",
      "6272/6272 [==============================] - 8s 1ms/step - loss: 0.7617 - acc: 0.7726 - val_loss: 1.3861 - val_acc: 0.6205\n",
      "Epoch 11/20\n",
      "6272/6272 [==============================] - 8s 1ms/step - loss: 0.7514 - acc: 0.7848 - val_loss: 1.3822 - val_acc: 0.6244\n",
      "Epoch 12/20\n",
      "6272/6272 [==============================] - 8s 1ms/step - loss: 0.6519 - acc: 0.7946 - val_loss: 1.3880 - val_acc: 0.6307\n",
      "Epoch 13/20\n",
      "6272/6272 [==============================] - 9s 1ms/step - loss: 0.5669 - acc: 0.8157 - val_loss: 1.4229 - val_acc: 0.6295\n",
      "Epoch 14/20\n",
      "6272/6272 [==============================] - 9s 1ms/step - loss: 0.5458 - acc: 0.8224 - val_loss: 1.4917 - val_acc: 0.6327\n",
      "Epoch 15/20\n",
      "6272/6272 [==============================] - 8s 1ms/step - loss: 0.5010 - acc: 0.8300 - val_loss: 1.5243 - val_acc: 0.6346\n",
      "Epoch 16/20\n",
      "6272/6272 [==============================] - 8s 1ms/step - loss: 0.4653 - acc: 0.8476 - val_loss: 1.6679 - val_acc: 0.6269\n",
      "Epoch 17/20\n",
      "6272/6272 [==============================] - 8s 1ms/step - loss: 0.4306 - acc: 0.8549 - val_loss: 1.7423 - val_acc: 0.6339\n",
      "Epoch 18/20\n",
      "6272/6272 [==============================] - 8s 1ms/step - loss: 0.4293 - acc: 0.8632 - val_loss: 1.7048 - val_acc: 0.6282\n",
      "Epoch 19/20\n",
      "6272/6272 [==============================] - 8s 1ms/step - loss: 0.3978 - acc: 0.8673 - val_loss: 1.8771 - val_acc: 0.6244\n",
      "Epoch 20/20\n",
      "6272/6272 [==============================] - 8s 1ms/step - loss: 0.3875 - acc: 0.8774 - val_loss: 1.9588 - val_acc: 0.6250\n",
      "1568/1568 [==============================] - 1s 495us/step\n",
      "1.9587573104975176 0.625\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 100)         198200    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                612       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 229,012\n",
      "Trainable params: 229,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=64,epochs=20,validation_data=(x_test,y_test))\n",
    "score,acc = model.evaluate(x_test,y_test,batch_size=64)\n",
    "print(score,acc)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "this_model = load_model('weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "制造稀缺\n"
     ]
    }
   ],
   "source": [
    "# 直接输入一句话对其进行预测\n",
    "def convert_vector_predict(str_r):\n",
    "    new_str = jieba.analyse.extract_tags(str_r,topK=20,withWeight=False,allowPOS=())\n",
    "#     print(new_str)\n",
    "    x = text_to_index_array(index_dict,[new_str])\n",
    "    x = sequence.pad_sequences(x,maxlen=50)\n",
    "#     print(x)\n",
    "    y = this_model.predict_classes(x)\n",
    "    return y\n",
    "value = convert_vector_predict('我用360借条一次性还清了所有欠款！')\n",
    "print([k for k,v in class_data.items() if v==value[0]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3(dl)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
